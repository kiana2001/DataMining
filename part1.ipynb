{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load your dataset\n",
        "# Replace '/path/to/your/dataset.csv' with the actual path to your dataset\n",
        "dataset_path = '/content/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Assuming you have 'Systolic Pressure' and 'Diastolic Pressure' columns\n",
        "# Calculate mean blood pressure\n",
        "df['Blood Pressure'] = (df['Systolic Pressure'] + 2 * df['Diastolic Pressure']) / 3\n",
        "\n",
        "# Create a binary column for 'High Blood Pressure' based on a threshold\n",
        "threshold = 140  # You can adjust this threshold as needed\n",
        "df['High Blood Pressure'] = (df['Blood Pressure'] > threshold).astype(int)\n",
        "\n",
        "# Select relevant columns for association rule mining\n",
        "selected_columns = ['Family History', 'High Blood Pressure']\n",
        "\n",
        "# Create a binary DataFrame for association rule mining\n",
        "binary_df = df[selected_columns]\n",
        "\n",
        "# Apply Apriori algorithm\n",
        "frequent_itemsets = apriori(binary_df, min_support=0.1, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.7)\n",
        "\n",
        "# Display the resulting association rules\n",
        "print(rules)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4jK4JR_XYV5",
        "outputId": "25f65781-2542-4e89-cdba-0de070967bc7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [antecedents, consequents, antecedent support, consequent support, support, confidence, lift, leverage, conviction, zhangs_metric]\n",
            "Index: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        ". **محاسبه میانگین فشار خون:**\n",
        "   \n",
        "   - میانگین فشار خون محاسبه شده و یک ستون جدید به نام 'فشار خون' به دیتافریم افزوده می‌شود.\n",
        "\n",
        ". **ایجاد ستون دودویی برای فشار خون بالا:**\n",
        "   - یک مقدار آستانه برای فشار خون بالا تعیین می‌شود (`threshold = 140`).\n",
        "   - یک ستون دودویی جدید به نام 'فشار خون بالا' بر اساس اینکه فشار خون محاسبه شده بالاتر از آستانه باشد یا خیر، ایجاد می‌شود.\n",
        "\n",
        ". **انتخاب ستون‌های مرتبط:**\n",
        "   - ستون‌های 'تاریخچه خانوادگی' و 'فشار خون بالا' برای انجام قوانین ارتباطی انتخاب می‌شوند.\n",
        "\n",
        ". **ایجاد دیتافریم دودویی:**\n",
        "   - یک دیتافریم جدید (`binary_df`) با شامل تنها ستون‌های انتخاب شده برای تحلیل ایجاد می‌شود.\n",
        "\n",
        ". **اعمال الگوریتم Apriori:**\n",
        "   - الگوریتم Apriori بر روی دیتافریم دودویی (`binary_df`) اجرا می‌شود تا مجموعه‌های آیتم متداول را پیدا کند.\n",
        "   - پارامتر `min_support=0.1` حداقل حمایت مورد نیاز برای یک مجموعه آیتم به عنوان متداول در نظر گرفته می‌شود.\n",
        "\n",
        ". **تولید قوانین ارتباطی:**\n",
        "   - قوانین ارتباطی از مجموعه‌های آیتم متداول با استفاده از تابع `association_rules` تولید می‌شوند.\n",
        "   - این قوانین بر اساس اطمینان ارزیابی می‌شوند، با تعیین حداقل اطمینان `0.7`.\n",
        "\n",
        ". **نمایش قوانین ارتباطی:**\n",
        "   - قوانین ارتباطی حاصل نمایش داده می‌شوند.\n",
        "\n",
        "در کل، این کد به پیش‌پردازش مجموعه داده مربوط به پیش‌بینی حمله قلب می‌پردازد، میانگین فشار خون را محاسبه می‌کند، نمایه دودویی فشار خون بالا را ایجاد می‌کند و سپس الگوریتم Apriori را برای کشف قوانین ارتباط بین 'تاریخچه خانوادگی' و 'فشار خون بالا' اعمال می‌کند. این قوانین ارتباط، برخی از الگوها یا روابط ممکن را در مجموعه داده که ممکن است برای پیش‌بینی حمله قلب مهم باشند، نشان می‌دهند. می‌توانید پارامترها را بر اساس ویژگی‌ها و اهداف خاص تجزیه و تحلیل خود تنظیم کنید."
      ],
      "metadata": {
        "id": "S9DZFCw6pn-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load the dataset\n",
        "dataset_path = '/content/drive/MyDrive/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Create bins for Cholesterol\n",
        "bins = [0, 199, 239, float('inf')]  # Adjust these boundaries based on your criteria\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['Cholesterol_Category'] = pd.cut(df['Cholesterol'], bins=bins, labels=labels, include_lowest=True)\n",
        "\n",
        "# Display unique values in the 'Cholesterol_Category' column\n",
        "print(\"Unique values in 'Cholesterol_Category':\", df['Cholesterol_Category'].unique())\n",
        "\n",
        "# Transform the DataFrame into a one-hot encoded format\n",
        "one_hot_encoded = pd.get_dummies(df, columns=['Cholesterol_Category', 'Heart Attack Risk'], drop_first=True)\n",
        "\n",
        "# chamge column name based on real names after get dummies\n",
        "one_hot_encoded_ch = one_hot_encoded[['Cholesterol_Low', 'Cholesterol_Medium', 'Cholesterol_High', 'Heart Attack Risk', 'Heart Attack Risk']]\n",
        "\n",
        "# Run Apriori to find frequent itemsets\n",
        "frequent_itemsets = apriori(one_hot_encoded, min_support=0.01, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
        "\n",
        "# Display results in the specified format\n",
        "result_df = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "id": "zkLTdU0sZy0Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "outputId": "7b7fc68b-6e85-4666-e448-303b2ecbcf8d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in 'Cholesterol_Category': ['Low', 'Medium', 'High']\n",
            "Categories (3, object): ['Low' < 'Medium' < 'High']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"None of [Index(['Cholesterol_Low', 'Cholesterol_Medium', 'Cholesterol_High',\\n       'Heart Attack Risk', 'Heart Attack Risk'],\\n      dtype='object')] are in the [columns]\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-85d215e973be>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# chamge column name based on real names after get dummies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mone_hot_encoded_ch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_encoded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Cholesterol_Low'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cholesterol_Medium'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Cholesterol_High'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Heart Attack Risk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Heart Attack Risk'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Run Apriori to find frequent itemsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3812\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3813\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3815\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6068\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6070\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6072\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6129\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6130\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6132\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Cholesterol_Low', 'Cholesterol_Medium', 'Cholesterol_High',\\n       'Heart Attack Risk', 'Heart Attack Risk'],\\n      dtype='object')] are in the [columns]\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "iHRQ2_fiJ4-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4945d162-9753-40ad-a906-3b882a6deb96"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "dataset_path = '/content/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "bins = [0, 199, 239, float('inf')]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['Cholesterol_Category'] = pd.cut(df['Cholesterol'], bins=bins, labels=labels, include_lowest=True)\n",
        "\n",
        "# Transform the DataFrame into a one-hot encoded format\n",
        "one_hot_encoded = pd.get_dummies(df, columns=['Cholesterol_Category', 'Heart Attack Risk'], drop_first=True)\n",
        "\n",
        "# Select the appropriate columns for one_hot_encoded_ch\n",
        "one_hot_encoded_ch = one_hot_encoded[['Cholesterol_Category_Medium', 'Cholesterol_Category_High', 'Heart Attack Risk_1']]\n",
        "\n",
        "frequent_itemsets = apriori(one_hot_encoded_ch, min_support=0.01, use_colnames=True)\n",
        "\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
        "\n",
        "result_df = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "id": "VrK4WneoLMRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00f11e8c-c0f3-42b7-a765-77c1ffd6bc33"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             antecedents                  consequents  support  confidence  \\\n",
            "0  (Heart Attack Risk_1)  (Cholesterol_Category_High)  0.21055    0.587823   \n",
            "\n",
            "       lift  \n",
            "0  1.019032  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```python\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load the dataset\n",
        "dataset_path = '/content/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "```\n",
        "\n",
        "- **توضیح:**\n",
        "  - در این بخش، کتابخانه‌های مورد نیاز برای اجرای کد، یعنی Pandas و ماژول‌های مربوط به الگوریتم Apriori و تولید قوانین ارتباط وارد می‌شوند.\n",
        "  - سپس مجموعه داده مرتبط با پیش‌بینی حمله قلب از یک فایل CSV خوانده می‌شود.\n",
        "\n",
        "```python\n",
        "# Create bins for cholesterol levels and categorize them\n",
        "bins = [0, 199, 239, float('inf')]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['Cholesterol_Category'] = pd.cut(df['Cholesterol'], bins=bins, labels=labels, include_lowest=True)\n",
        "```\n",
        "\n",
        "- **توضیح:**\n",
        "  - این بخش، داده‌های مربوط به سطوح کلسترول را به سه دسته (پایین، متوسط و بالا) تقسیم می‌کند و در ستون جدیدی به نام 'Cholesterol_Category' ذخیره می‌کند.\n",
        "\n",
        "```python\n",
        "# Transform the DataFrame into a one-hot encoded format\n",
        "one_hot_encoded = pd.get_dummies(df, columns=['Cholesterol_Category', 'Heart Attack Risk'], drop_first=True)\n",
        "```\n",
        "\n",
        "- **توضیح:**\n",
        "  - این بخش، دیتافریم را به یک فرمت یک-هات (One-Hot Encoding) تبدیل می‌کند.\n",
        "  - ستون‌های 'Cholesterol_Category' و 'Heart Attack Risk' به فرمت یک-هات تبدیل می‌شوند و ستون‌های اصلی حذف می‌شوند.\n",
        "\n",
        "```python\n",
        "# Select the appropriate columns for association rule mining\n",
        "one_hot_encoded_ch = one_hot_encoded[['Cholesterol_Category_Medium', 'Cholesterol_Category_High', 'Heart Attack Risk_1']]\n",
        "```\n",
        "\n",
        "- **توضیح:**\n",
        "  - این بخش، ستون‌های مورد نیاز برای انجام کاوش قوانین ارتباط را انتخاب می‌کند.\n",
        "  - ستون‌های 'Cholesterol_Category_Medium'، 'Cholesterol_Category_High' و 'Heart Attack Risk_1' انتخاب می‌شوند.\n",
        "\n",
        "```python\n",
        "# Apply Apriori algorithm\n",
        "frequent_itemsets = apriori(one_hot_encoded_ch, min_support=0.01, use_colnames=True)\n",
        "```\n",
        "\n",
        "- **توضیح:**\n",
        "  - این بخش، الگوریتم Apriori را بر روی دیتافریم یک-هات اعمال کرده و مجموعه‌های آیتم متداول را پیدا می‌کند.\n",
        "  - پارامتر `min_support=0.01` حداقل حمایت مورد نیاز برای یک مجموعه آیتم به عنوان متداول در نظر گرفته می‌شود.\n",
        "\n",
        "```python\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
        "```\n",
        "\n",
        "- **توضیح:**\n",
        "  - این بخش، قوانین ارتباط را از مجموعه‌های آیتم متداول با استفاده از تابع `association_rules` تولید می‌کند.\n",
        "  - قوانین بر اساس اطمینان ارزیابی می‌شوند و حداقل اطمینان مورد نیاز به `0.5` تنظیم شده است.\n",
        "\n",
        "```python\n",
        "# Extract relevant information from the rules\n",
        "result_df = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
        "```\n",
        "\n",
        "- **توضیح:**\n",
        "  - این بخش، اطلاعات مرتبط با قوانین تولید شده از قوانین ارتباط را استخراج می‌کند.\n",
        "  - اطلاعات مهم شامل \"پیش‌موندها\"، \"پس‌موندها\"، \"حمایت\"، \"اطمینان\" و \"لیفت\" می‌باشند.\n",
        "\n",
        "```python\n",
        "# Display the resulting association rules\n",
        "print(result_df)\n",
        "```\n",
        "\n",
        "- **توضیح:**\n",
        "  - در نهایت، این بخش، قوانین ارتباطی که استخراج شده‌اند را چاپ می‌کند و نتیجه را به کاربر نمایش می‌دهد."
      ],
      "metadata": {
        "id": "KJ9GfB-ArPCI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W_hXu1qUrOp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load your dataset\n",
        "dataset_path = '/content/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Assuming 'Family History' and 'Heart Attack Risk' are column names in your DataFrame\n",
        "one_hot_encoded = pd.get_dummies(df[['Family History', 'Heart Attack Risk']], prefix='', prefix_sep='')\n",
        "\n",
        "# Adjust min_support if needed\n",
        "min_support = 0.01\n",
        "frequent_itemsets = apriori(one_hot_encoded, min_support=min_support, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
        "\n",
        "# Display results\n",
        "result_df = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "id": "9FMR2kBZTuFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aac24f4-c788-474c-892f-154263b56c2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [antecedents, consequents, support, confidence, lift]\n",
            "Index: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```python\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load your dataset\n",
        "dataset_path = '/content/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "```\n",
        "- **توضیح:** ابتدا کتابخانه‌های مورد نیاز، pandas برای تیمار داده‌ها و mlxtend برای الگوریتم Apriori و تولید قوانین ارتباط وارد شده‌اند. سپس مجموعه داده مرتبط با پیش‌بینی حمله قلب از یک فایل CSV خوانده می‌شود.\n",
        "\n",
        "```python\n",
        "# Assuming 'Family History' and 'Heart Attack Risk' are column names in your DataFrame\n",
        "one_hot_encoded = pd.get_dummies(df[['Family History', 'Heart Attack Risk']], prefix='', prefix_sep='')\n",
        "```\n",
        "- **توضیح:** در این مرحله، ستون‌های 'Family History' و 'Heart Attack Risk' تبدیل به فرمت یک-هات شده‌اند. یعنی هر مقدار یک ستون به یک ستون جدید با نام تغییر یافته تبدیل می‌شود (one-hot encoding).\n",
        "\n",
        "```python\n",
        "# Adjust min_support if needed\n",
        "min_support = 0.01\n",
        "frequent_itemsets = apriori(one_hot_encoded, min_support=min_support, use_colnames=True)\n",
        "```\n",
        "- **توضیح:** اینجا الگوریتم Apriori بر روی دیتافریم یک-هات اعمال می‌شود. `min_support` حداقل حمایت مورد نیاز برای یک مجموعه آیتم به عنوان متداول در نظر گرفته می‌شود.\n",
        "\n",
        "```python\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
        "```\n",
        "- **توضیح:** در این مرحله، قوانین ارتباط با استفاده از مجموعه‌های آیتم متداول تولید می‌شوند. `metric='confidence'` نشان دهنده این است که ارتباط‌ها بر اساس اطمینان (confidence) ارزیابی می‌شوند و `min_threshold=0.5` حداقل اطمینان مورد نیاز برای نمایش یک قانون ارتباط را تعیین می‌کند.\n",
        "\n",
        "```python\n",
        "# Display results\n",
        "result_df = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
        "print(result_df)\n",
        "```\n",
        "- **توضیح:** در نهایت، نتایج به صورت DataFrame نمایش داده می‌شود که شامل 'پیش‌موندها'، 'پس‌موندها'، 'حمایت'، 'اطمینان' و 'لیفت' می‌باشد.\n",
        "\n",
        "**مدل Apriori:**\n",
        "- الگوریتم Apriori یک الگوریتم کاوش قوانین ارتباط است که در داده‌های فراوان به دنبال الگوهای متداول یا آیتم‌های مشترک می‌گردد. این الگوریتم بر اساس مفهومی به نام \"خاصیت آپریوری\" عمل می‌کند که به آن امکان می‌دهد که اگر یک مجموعه آیتم متداول باشد، هر زیرمجموعه آن نیز متداول باشد.\n",
        "\n",
        "**قوانین ارتباط:**\n",
        "- قوانین ارتباط به عنوان نتیجه‌ای از اجرای الگوریتم Apriori حاصل می‌شوند. این قوانین شامل یک مجموعه از آیتم‌های ورودی (پیش‌موندها) و آیتم‌های خروجی (پس‌موندها) هستند که با یکدیگر در داده‌ها ارتباط دارند. معیارهایی مانند حمایت، اطمینان و لیفت نیز میزان قوت این قوانین را ارزیابی می‌کنند."
      ],
      "metadata": {
        "id": "K4UmkxGRsuhc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load your dataset\n",
        "dataset_path = '/content/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Assuming 'Smoking' and 'Heart Attack Risk' are column names in your DataFrame\n",
        "one_hot_encoded = pd.get_dummies(df[['Smoking', 'Heart Attack Risk']], prefix='', prefix_sep='')\n",
        "\n",
        "# Adjust min_support if needed\n",
        "min_support = 0.01\n",
        "frequent_itemsets = apriori(one_hot_encoded, min_support=min_support, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
        "\n",
        "# Display results\n",
        "result_df = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "id": "m783T9yYW6d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcaf63d0-b434-4e6e-f386-591162acd75e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           antecedents consequents   support  confidence      lift\n",
            "0  (Heart Attack Risk)   (Smoking)  0.320621    0.895123  0.998152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load your dataset\n",
        "dataset_path = '/content/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Assuming 'Obesity' and 'Heart Attack Risk' are column names in your DataFrame\n",
        "one_hot_encoded = pd.get_dummies(df[['Obesity', 'Heart Attack Risk']], prefix='', prefix_sep='')\n",
        "\n",
        "# Adjust min_support if needed\n",
        "min_support = 0.01\n",
        "frequent_itemsets = apriori(one_hot_encoded, min_support=min_support, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
        "\n",
        "# Display results\n",
        "result_df = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "id": "LPg4rFp8mo0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e8dc657-7602-4987-bb0a-f9f0a934508f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [antecedents, consequents, support, confidence, lift]\n",
            "Index: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load your dataset\n",
        "dataset_path = '/content/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Assuming 'Obesity' and 'Heart Attack Risk' are column names in your DataFrame\n",
        "one_hot_encoded = pd.get_dummies(df[['Obesity', 'Heart Attack Risk']], prefix='', prefix_sep='')\n",
        "\n",
        "# Adjust min_support if needed\n",
        "min_support = 0.01\n",
        "frequent_itemsets = apriori(one_hot_encoded, min_support=min_support, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
        "\n",
        "# Display results\n",
        "result_df = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "id": "gJqPKg1cnCVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3db4ff63-2305-49a8-e56f-737e1c3b3f31"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [antecedents, consequents, support, confidence, lift]\n",
            "Index: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load your dataset\n",
        "dataset_path = '/content/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Assuming 'Alcohol Consumption' and 'Heart Attack Risk' are column names in your DataFrame\n",
        "one_hot_encoded = pd.get_dummies(df[['Alcohol Consumption', 'Heart Attack Risk']], prefix='', prefix_sep='')\n",
        "\n",
        "# Adjust min_support if needed\n",
        "min_support = 0.01\n",
        "frequent_itemsets = apriori(one_hot_encoded, min_support=min_support, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
        "\n",
        "# Display results\n",
        "result_df = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "id": "r-UccqRqnmP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72b969ba-2d27-4002-8b41-ee0754189fc3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           antecedents            consequents   support  confidence      lift\n",
            "0  (Heart Attack Risk)  (Alcohol Consumption)  0.211007    0.589098  0.984979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load your dataset\n",
        "dataset_path = '/content/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Assuming 'Exercise Hours Per Week' and 'Heart Attack Risk' are column names in your DataFrame\n",
        "one_hot_encoded = pd.get_dummies(df[['Exercise Hours Per Week', 'Heart Attack Risk']], prefix='', prefix_sep='')\n",
        "\n",
        "# Adjust min_support if needed\n",
        "min_support = 0.01\n",
        "frequent_itemsets = apriori(one_hot_encoded, min_support=min_support, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
        "\n",
        "# Display results\n",
        "result_df = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "id": "diPEGEBDnoeH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "outputId": "d896ba3a-02ba-4db5-e196-3d8c3e7b300c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The allowed values for a DataFrame are True, False, 0, 1. Found value 8.123736391",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3935b8549c80>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Adjust min_support if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmin_support\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfrequent_itemsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapriori\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_support\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_support\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_colnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Generate association rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/apriori.py\u001b[0m in \u001b[0;36mapriori\u001b[0;34m(df, min_support, use_colnames, max_len, verbose, low_memory)\u001b[0m\n\u001b[1;32m    239\u001b[0m         )\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0mfpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_input_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sparse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py\u001b[0m in \u001b[0;36mvalid_input_check\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;34m\" are True, False, 0, 1. Found value %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             )\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The allowed values for a DataFrame are True, False, 0, 1. Found value 8.123736391"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load your dataset\n",
        "dataset_path = '/content/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Define bins and labels for categorizing Exercise Hours\n",
        "exercise_bins = [0, 4, 8, float('inf')]\n",
        "exercise_labels = ['Low', 'Medium', 'High']\n",
        "\n",
        "# Create a new column 'Exercise_Category' based on Exercise Hours\n",
        "df['Exercise_Category'] = pd.cut(df['Exercise Hours Per Week'], bins=exercise_bins, labels=exercise_labels, include_lowest=True)\n",
        "\n",
        "# Display unique values in 'Exercise_Category'\n",
        "print(\"Unique values in 'Exercise_Category':\", df['Exercise_Category'].unique())\n",
        "\n",
        "# One-hot encode the categorical columns\n",
        "one_hot_encoded = pd.get_dummies(df, columns=['Exercise_Category', 'Heart Attack Risk'], drop_first=True)\n",
        "\n",
        "# Get the actual column names after one-hot encoding\n",
        "exercise_cols = [col for col in one_hot_encoded.columns if 'Exercise_Category' in col]\n",
        "\n",
        "# Select the appropriate columns for analysis\n",
        "one_hot_encoded_exercise = one_hot_encoded[exercise_cols + ['Heart Attack Risk_1']]\n",
        "\n",
        "# Apply Apriori algorithm\n",
        "frequent_itemsets = apriori(one_hot_encoded_exercise, min_support=0.01, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
        "\n",
        "# Display results\n",
        "result_df = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "id": "7egrcAZZpJww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93aaa94d-55f4-415b-9b49-e779998e9d19"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in 'Exercise_Category': ['High', 'Medium', 'Low']\n",
            "Categories (3, object): ['Low' < 'Medium' < 'High']\n",
            "             antecedents               consequents   support  confidence  \\\n",
            "0  (Heart Attack Risk_1)  (Exercise_Category_High)  0.218771    0.610775   \n",
            "\n",
            "       lift  \n",
            "0  1.010229  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```python\n",
        "# دیتاست را بارگذاری کنید\n",
        "dataset_path = '/content/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "```\n",
        "- دیتاست پیش‌بینی حمله قلب از مسیر مشخص شده خوانده می‌شود.\n",
        "\n",
        "```python\n",
        "# بازه‌ها و برچسب‌ها را برای دسته‌بندی ساعت‌های ورزش تعریف کنید\n",
        "exercise_bins = [0, 4, 8, float('inf')]\n",
        "exercise_labels = ['Low', 'Medium', 'High']\n",
        "```\n",
        "- بازه‌ها و برچسب‌ها برای دسته‌بندی 'ساعت‌های ورزش هفتگی' به سه دسته: کم، متوسط و زیاد تعریف می‌شوند.\n",
        "\n",
        "```python\n",
        "# یک ستون جدید 'Exercise_Category' بر اساس ساعت‌های ورزش ایجاد کنید\n",
        "df['Exercise_Category'] = pd.cut(df['Exercise Hours Per Week'], bins=exercise_bins, labels=exercise_labels, include_lowest=True)\n",
        "```\n",
        "- یک ستون جدید دسته‌بندی‌شده به نام 'Exercise_Category' بر اساس بازه‌های تعریف شده برای 'ساعت‌های ورزش هفتگی' ایجاد می‌شود.\n",
        "\n",
        "```python\n",
        "# مقادیر یکتا در 'Exercise_Category' را نمایش دهید\n",
        "print(\"Unique values in 'Exercise_Category':\", df['Exercise_Category'].unique())\n",
        "```\n",
        "- مقادیر یکتا در ستون 'Exercise_Category' جدید را چاپ کنید.\n",
        "\n",
        "```python\n",
        "one_hot_encoded = pd.get_dummies(df, columns=['Exercise_Category', 'Heart Attack Risk'], drop_first=True)\n",
        "```\n",
        "\n",
        "```python\n",
        "# نام‌های ستون‌های واقعی پس از هات کد کردن را دریافت کنید\n",
        "exercise_cols = [col for col in one_hot_encoded.columns if 'Exercise_Category' in col]\n",
        "```\n",
        "- نام‌های ستون‌های مرتبط با 'Exercise_Category' را بعد از یک-هات کد کردن به دست می‌آورد.\n",
        "\n",
        "```python\n",
        "# ستون‌های مناسب برای تحلیل را انتخاب کنید\n",
        "one_hot_encoded_exercise = one_hot_encoded[exercise_cols + ['Heart Attack Risk_1']]\n",
        "```\n",
        "- ستون‌های مرتبط با تحلیل قوانین ارتباط را انتخاب می‌کند.\n",
        "\n",
        "```python\n",
        "# الگوریتم Apriori را اعمال کنید\n",
        "frequent_itemsets = apriori(one_hot_encoded_exercise, min_support=0.01, use_colnames=True)\n",
        "```\n",
        "- الگوریتم Apriori را بر روی دیتافریم یک-هات اعمال کرده و مجموعه‌های آیتم متداول را پیدا می‌کند.\n",
        "\n",
        "```python\n",
        "# قوانین ارتباط را تولید کنید\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
        "```\n",
        "- قوانین ارتباط را بر اساس مجموعه‌های آیتم متداول تولید می‌کند و از اطمینان به عنوان معیار ارزیابی استفاده می‌کند.\n",
        "\n",
        "```python\n",
        "# نتایج را نمایش دهید\n",
        "result_df = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
        "print(result_df)\n",
        "```\n",
        "- نتایج حاصل از قوانین ارتباط را نمایش می‌دهد که شامل پیش‌موندها، پس‌موندها، حمایت، اطمینان و لیفت می‌باشد."
      ],
      "metadata": {
        "id": "MBpdSxZQtR1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load your dataset\n",
        "dataset_path = '/content/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Define bins and labels for categorizing Systolic Pressure\n",
        "systolic_bins = [0, 120, 130, 140, 160, 180, 200, float('inf')]\n",
        "systolic_labels = ['<120', '120-130', '130-140', '140-160', '160-180', '180-200', '>=200']\n",
        "\n",
        "# Define bins and labels for categorizing Diastolic Pressure\n",
        "diastolic_bins = [0, 80, 90, 100, 110, 120, 130, float('inf')]\n",
        "diastolic_labels = ['<80', '80-90', '90-100', '100-110', '110-120', '120-130', '>=130']\n",
        "\n",
        "# Create new columns 'Systolic_Pressure_Category' and 'Diastolic_Pressure_Category'\n",
        "df['Systolic_Pressure_Category'] = pd.cut(df['Systolic Pressure'], bins=systolic_bins, labels=systolic_labels, include_lowest=True)\n",
        "df['Diastolic_Pressure_Category'] = pd.cut(df['Diastolic Pressure'], bins=diastolic_bins, labels=diastolic_labels, include_lowest=True)\n",
        "\n",
        "# Display unique values in the new columns\n",
        "print(\"Unique values in 'Systolic_Pressure_Category':\", df['Systolic_Pressure_Category'].unique())\n",
        "print(\"Unique values in 'Diastolic_Pressure_Category':\", df['Diastolic_Pressure_Category'].unique())\n",
        "\n",
        "# One-hot encode the categorical columns\n",
        "one_hot_encoded = pd.get_dummies(df, columns=['Systolic_Pressure_Category', 'Diastolic_Pressure_Category', 'Heart Attack Risk'], drop_first=True)\n",
        "\n",
        "# Get the actual column names after one-hot encoding\n",
        "systolic_pressure_cols = [col for col in one_hot_encoded.columns if 'Systolic_Pressure_Category' in col]\n",
        "diastolic_pressure_cols = [col for col in one_hot_encoded.columns if 'Diastolic_Pressure_Category' in col]\n",
        "\n",
        "# Select the appropriate columns for analysis\n",
        "one_hot_encoded_pressure = one_hot_encoded[systolic_pressure_cols + diastolic_pressure_cols + ['Heart Attack Risk_1']]\n",
        "\n",
        "# Apply Apriori algorithm\n",
        "frequent_itemsets = apriori(one_hot_encoded_pressure, min_support=0.01, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
        "\n",
        "# Display results\n",
        "result_df = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "id": "_Bsz0OMWr8Z6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5413ed90-6559-4866-8bc6-5c27334dd789"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values in 'Systolic_Pressure_Category': ['140-160', '<120', '160-180', '130-140', '120-130']\n",
            "Categories (7, object): ['<120' < '120-130' < '130-140' < '140-160' < '160-180' < '180-200' < '>=200']\n",
            "Unique values in 'Diastolic_Pressure_Category': ['80-90', '90-100', '100-110', '<80']\n",
            "Categories (7, object): ['<80' < '80-90' < '90-100' < '100-110' < '110-120' < '120-130' < '>=130']\n",
            "Empty DataFrame\n",
            "Columns: [antecedents, consequents, support, confidence, lift]\n",
            "Index: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load your dataset\n",
        "dataset_path = '/content/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Assuming 'Sex' and 'Heart Attack Risk' are column names in your DataFrame\n",
        "one_hot_encoded = pd.get_dummies(df[['Sex', 'Heart Attack Risk']], prefix='', prefix_sep='')\n",
        "\n",
        "# Adjust min_support if needed\n",
        "min_support = 0.01\n",
        "frequent_itemsets = apriori(one_hot_encoded, min_support=min_support, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
        "\n",
        "# Display results\n",
        "result_df = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "id": "miadIBqgvML_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359fcea6-191d-4c11-850d-14949cb0a2f1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           antecedents consequents  support  confidence      lift\n",
            "0  (Heart Attack Risk)      (Male)   0.2504    0.699076  1.002539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# Load your dataset\n",
        "dataset_path = '/content/heart_attack_prediction_dataset_cleaned.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Assuming 'Age' and 'Heart Attack Risk' are column names in your DataFrame\n",
        "bins = [29, 39, 49, 59, 69, 79, 89, 99]\n",
        "labels = ['30-39', '40-49', '50-59', '60-69', '70-79', '80-89', '90-99']\n",
        "df['Age_Category'] = pd.cut(df['Age'], bins=bins, labels=labels, include_lowest=True)\n",
        "\n",
        "one_hot_encoded = pd.get_dummies(df[['Age_Category', 'Heart Attack Risk']], prefix='', prefix_sep='')\n",
        "\n",
        "# Adjust min_support if needed\n",
        "min_support = 0.01\n",
        "frequent_itemsets = apriori(one_hot_encoded, min_support=min_support, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric='confidence', min_threshold=0.5)\n",
        "\n",
        "# Display results\n",
        "result_df = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']]\n",
        "print(result_df)\n"
      ],
      "metadata": {
        "id": "m0Ckfxp1vd0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b87de7d-4d8c-4a4d-9ea1-a19c359ae724"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [antecedents, consequents, support, confidence, lift]\n",
            "Index: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}